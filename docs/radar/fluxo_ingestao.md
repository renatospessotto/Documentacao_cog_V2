# üîÑ Fluxo de Ingest√£o do Radar

## üìã Vis√£o Geral do Pipeline

O fluxo de ingest√£o do Radar segue um pipeline estruturado que move dados do MySQL para S3, garantindo alta disponibilidade e integridade dos dados.

```mermaid
sequenceDiagram
    participant AF as Airflow
    participant AB as Airbyte
    participant MySQL as MySQL Radar
    participant S3 as S3 Bronze
    participant Glue as AWS Glue
    participant BI as Power BI

    Note over AF: Diariamente √†s 2h UTC
    AF->>AB: Trigger sync (connection_mysql_s3_radar)
    AB->>MySQL: Connect (bi-cognitivo-read)
    MySQL->>AB: Query all tables (80+)
    AB->>AB: Transform to Parquet + SNAPPY
    AB->>S3: Write to bronze_radar/
    AB->>AF: Completion status
    AF->>AF: Send Slack notification
    
    Note over Glue: Post-ingest√£o
    S3->>Glue: Auto-trigger crawler
    Glue->>BI: Schema updated
```

## üöÄ Etapas Detalhadas

### **1. Prepara√ß√£o e Valida√ß√£o**

#### **1.1 Verifica√ß√£o de Conectividade**
```bash
# Teste de conex√£o MySQL
mysql -h db-mysql-radar-production.cxsfxyp2ge90.us-east-2.rds.amazonaws.com \
      -P 3306 \
      -u bi-cognitivo-read \
      -p radar \
      --ssl-mode=PREFERRED \
      -e "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='radar';"
```

#### **1.2 Valida√ß√£o de Credenciais S3**
```bash
# Teste de acesso S3
aws s3 ls s3://farmarcas-production-bronze/origin=airbyte/database=bronze_radar/ \
  --region us-east-2
```

### **2. In√≠cio da Sincroniza√ß√£o**

#### **2.1 Trigger via Airflow**
```python
# DAG: dag_sync_airbyte_connections
from airflow.providers.airbyte.operators.airbyte import AirbyteTriggerSyncOperator

trigger_radar_sync = AirbyteTriggerSyncOperator(
    task_id='trigger_sync_radar',
    airbyte_conn_id='airbyte_default',
    connection_id='6c7fda57-ebdb-4c6b-9bc3-6b5d5cb9e1ad',  # connection_mysql_s3_radar
    asynchronous=True,
    timeout=3600,
    wait_seconds=30
)
```

#### **2.2 Configura√ß√£o de Sync**
- **Modo**: Full Refresh
- **Frequ√™ncia**: Manual (controlado pelo Airflow)
- **Timeout**: 3600 segundos
- **Retry**: 3 tentativas com backoff exponencial

### **3. Extra√ß√£o dos Dados**

#### **3.1 Conex√£o Source MySQL**
```yaml
# Configura√ß√£o da fonte
host: db-mysql-radar-production.cxsfxyp2ge90.us-east-2.rds.amazonaws.com
port: 3306
database: radar
username: bi-cognitivo-read
ssl: true
ssl_mode: preferred
replication_method: STANDARD
```

#### **3.2 Tabelas Extra√≠das (80+ tabelas)**

##### **Principais Categorias:**

**üè™ Farm√°cias e Lojas**
- `store` - Dados cadastrais das farm√°cias
- `store_metrics` - M√©tricas de performance
- `store_general_strategy` - Estrat√©gias comerciais
- `store_document` - Documenta√ß√£o legal
- `store_distributor` - Relacionamento com distribuidores

**üë• Usu√°rios e Acesso**
- `user_access` - Controle de acesso
- `user_store` - V√≠nculo usu√°rio-farm√°cia
- `user_document` - Documentos dos usu√°rios
- `user_terms` - Termos aceitos

**üì¶ Produtos e Cat√°logo**
- `product` - Cat√°logo de produtos
- `product_ean` - C√≥digos EAN
- `product_pbm` - Dados PBM (Pharmacy Benefit Management)
- `product_category` - Categoriza√ß√£o

**üéØ Campanhas e Concursos**
- `contest` - Campanhas ativas
- `contest_objective` - Objetivos das campanhas
- `contest_score` - Pontua√ß√µes
- `voucher` - Vouchers e benef√≠cios

**üìä Analytics e M√©tricas**
- `brand_metrics_average` - M√©tricas m√©dias por marca
- `performance_indicators` - KPIs de performance
- `dashboard_data` - Dados para dashboards

### **4. Transforma√ß√£o e Carregamento**

#### **4.1 Processamento Airbyte**
```yaml
# Configura√ß√£o do processamento
format_type: Parquet
compression_codec: SNAPPY
page_size_kb: 1024
block_size_mb: 128
dictionary_encoding: true
max_padding_size_mb: 8
```

#### **4.2 Estrutura de Destino S3**
```
s3://farmarcas-production-bronze/
‚îî‚îÄ‚îÄ origin=airbyte/database=bronze_radar/
    ‚îú‚îÄ‚îÄ store/
    ‚îÇ   ‚îî‚îÄ‚îÄ cog_dt_ingestion=2024-01-15/
    ‚îÇ       ‚îú‚îÄ‚îÄ file_store_001.parquet
    ‚îÇ       ‚îî‚îÄ‚îÄ file_store_002.parquet
    ‚îú‚îÄ‚îÄ store_metrics/
    ‚îÇ   ‚îî‚îÄ‚îÄ cog_dt_ingestion=2024-01-15/
    ‚îú‚îÄ‚îÄ user_access/
    ‚îÇ   ‚îî‚îÄ‚îÄ cog_dt_ingestion=2024-01-15/
    ‚îî‚îÄ‚îÄ [demais_tabelas]/
```

#### **4.3 Metadados e Particionamento**
- **Parti√ß√£o Principal**: `cog_dt_ingestion` (data de ingest√£o)
- **Formato de Data**: YYYY-MM-DD
- **Compress√£o**: SNAPPY para otimiza√ß√£o de performance
- **Schema Evolution**: Suportado via Airbyte

### **5. Valida√ß√£o e Monitoramento**

#### **5.1 Verifica√ß√µes Autom√°ticas**
```python
# Valida√ß√£o p√≥s-ingest√£o
def validate_radar_ingestion(execution_date):
    """Valida se a ingest√£o foi bem-sucedida"""
    
    # 1. Verificar se todos os arquivos foram criados
    expected_tables = get_radar_table_list()
    s3_objects = list_s3_objects(
        bucket='farmarcas-production-bronze',
        prefix=f'origin=airbyte/database=bronze_radar/',
        date=execution_date
    )
    
    # 2. Validar contagem de registros
    for table in expected_tables:
        record_count = count_parquet_records(s3_objects[table])
        if record_count == 0:
            raise ValueError(f"Tabela {table} sem registros")
    
    # 3. Verificar integridade dos arquivos
    validate_parquet_integrity(s3_objects)
    
    return True
```

#### **5.2 M√©tricas de Monitoramento**
- **Dura√ß√£o da Sync**: Tempo total de sincroniza√ß√£o
- **Volume de Dados**: N√∫mero de registros por tabela
- **Tamanho dos Arquivos**: Volume em MB/GB transferido
- **Taxa de Erro**: Percentual de falhas por execu√ß√£o

### **6. Notifica√ß√µes e Alertas**

#### **6.1 Sucesso**
```python
# Notifica√ß√£o de sucesso
slack_success = SlackWebhookOperator(
    task_id='notify_success',
    http_conn_id='slack_webhook',
    message="""
    ‚úÖ *Radar Sync Completed*
    
    ‚Ä¢ Duration: {{ ti.duration }}
    ‚Ä¢ Tables: 80+ synchronized
    ‚Ä¢ Records: {{ ti.xcom_pull('count_records') }}
    ‚Ä¢ S3 Path: s3://farmarcas-production-bronze/origin=airbyte/database=bronze_radar/
    ‚Ä¢ Date: {{ ds }}
    """,
    channel='#data-engineering'
)
```

#### **6.2 Falha**
```python
# Notifica√ß√£o de falha
def task_fail_slack_alert(context):
    slack_msg = f"""
    üö® *Radar Sync Failed*
    
    ‚Ä¢ Task: {context.get('task_instance').task_id}
    ‚Ä¢ DAG: {context.get('task_instance').dag_id}
    ‚Ä¢ Execution Time: {context.get('execution_date')}
    ‚Ä¢ Error: {context.get('exception')}
    ‚Ä¢ Log: {context.get('task_instance').log_url}
    """
    send_slack_notification(slack_msg)
```

## ‚è±Ô∏è Cronograma e Frequ√™ncia

### **Agenda de Execu√ß√£o**
- **Hor√°rio**: 2:00 UTC (23:00 BRT / 22:00 BRT no hor√°rio de ver√£o)
- **Frequ√™ncia**: Di√°ria
- **Dura√ß√£o M√©dia**: 45-60 minutos
- **Janela de Manuten√ß√£o**: 1:00-3:00 UTC

### **SLA e Disponibilidade**
- **SLA de Conclus√£o**: 3:00 UTC
- **Disponibilidade**: 99.5% mensal
- **RTO**: 4 horas para restaura√ß√£o
- **RPO**: 24 horas (√∫ltima sincroniza√ß√£o bem-sucedida)

## üîÑ Processo de Recovery

### **Em Caso de Falha**

#### **1. Diagn√≥stico Inicial**
```bash
# Verificar status da conex√£o Airbyte
curl -X GET "http://airbyte-server:8001/api/v1/connections/6c7fda57-ebdb-4c6b-9bc3-6b5d5cb9e1ad" \
  -H "accept: application/json"

# Verificar logs do Airflow
airflow logs dag_sync_airbyte_connections trigger_sync_radar 2024-01-15
```

#### **2. Reprocessamento**
```python
# Trigger manual via Airflow CLI
airflow dags trigger dag_sync_airbyte_connections \
  --conf '{"connection_id": "6c7fda57-ebdb-4c6b-9bc3-6b5d5cb9e1ad"}'
```

#### **3. Valida√ß√£o P√≥s-Recovery**
```bash
# Verificar dados no S3
aws s3 ls s3://farmarcas-production-bronze/origin=airbyte/database=bronze_radar/ \
  --recursive --human-readable --summarize
```

## üìà Otimiza√ß√µes e Melhorias

### **Performance**
- **Paraleliza√ß√£o**: M√∫ltiplas tabelas sincronizadas simultaneamente
- **Compress√£o**: SNAPPY para balance entre compress√£o e velocidade
- **Batch Size**: Otimizado para tabelas de diferentes tamanhos

### **Confiabilidade**
- **Health Checks**: Valida√ß√£o cont√≠nua de conectividade
- **Retry Logic**: Tentativas autom√°ticas em caso de falha tempor√°ria
- **Circuit Breaker**: Parada autom√°tica em caso de falhas consecutivas

### **Escalabilidade**
- **Resource Management**: Aloca√ß√£o din√¢mica de recursos Airbyte
- **Auto-scaling**: Ajuste autom√°tico baseado no volume de dados
- **Load Balancing**: Distribui√ß√£o de carga entre workers

---

**üìç Pr√≥ximos Passos:**
- [Ferramentas e Servi√ßos](ferramentas_servicos.md)
- [Pr√©-requisitos](pre_requisitos.md)
- [Configura√ß√µes de Exemplo](configuracoes_exemplo.md)
