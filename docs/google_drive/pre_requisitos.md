# ‚öôÔ∏è Pr√©-requisitos - Google Drive Collector

## üìã Vis√£o Geral

Este documento detalha todos os pr√©-requisitos necess√°rios para configurar e executar o Google Drive Collector, incluindo autentica√ß√£o Google Drive API, permiss√µes AWS, depend√™ncias Python e configura√ß√µes de ambiente.

---

## üîê 1. Autentica√ß√£o Google Drive API

### **1.1 Configura√ß√£o Service Account**

#### **Passo 1: Criar Projeto no Google Cloud Console**
```bash
# 1. Acesse https://console.cloud.google.com/
# 2. Crie novo projeto ou selecione existente
# 3. Nome sugerido: "farmarcas-data-platform"
# 4. Anote o PROJECT_ID para refer√™ncia
```

#### **Passo 2: Habilitar Google Drive API**
```bash
# Via Cloud Console:
# 1. V√° para "APIs & Services" > "Library"
# 2. Busque por "Google Drive API"
# 3. Clique em "Enable"

# Via gcloud CLI (opcional):
gcloud services enable drive.googleapis.com --project=farmarcas-data-platform
```

#### **Passo 3: Criar Service Account**
```bash
# Via Cloud Console:
# 1. V√° para "IAM & Admin" > "Service Accounts"
# 2. Clique "Create Service Account"
# 3. Nome: "gdrive-collector"
# 4. Descri√ß√£o: "Service account para coleta de arquivos do Google Drive"
# 5. N√£o atribuir roles no projeto (desnecess√°rio)

# Via gcloud CLI:
gcloud iam service-accounts create gdrive-collector \
    --description="Service account para coleta Google Drive" \
    --display-name="Google Drive Collector" \
    --project=farmarcas-data-platform
```

#### **Passo 4: Gerar Chave JSON**
```bash
# Via Cloud Console:
# 1. Clique no Service Account criado
# 2. V√° para aba "Keys"
# 3. Clique "Add Key" > "Create new key"
# 4. Selecione "JSON"
# 5. Fa√ßa download do arquivo

# Via gcloud CLI:
gcloud iam service-accounts keys create google_service_account.json \
    --iam-account=gdrive-collector@farmarcas-data-platform.iam.gserviceaccount.com \
    --project=farmarcas-data-platform
```

### **1.2 Estrutura do Arquivo Credentials**

O arquivo JSON deve ter a seguinte estrutura:

```json
{
  "type": "service_account",
  "project_id": "farmarcas-data-platform",
  "private_key_id": "abc123def456...",
  "private_key": "-----BEGIN PRIVATE KEY-----\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQC...\n-----END PRIVATE KEY-----\n",
  "client_email": "gdrive-collector@farmarcas-data-platform.iam.gserviceaccount.com",
  "client_id": "123456789012345678901",
  "auth_uri": "https://accounts.google.com/o/oauth2/auth",
  "token_uri": "https://oauth2.googleapis.com/token",
  "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
  "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/gdrive-collector%40farmarcas-data-platform.iam.gserviceaccount.com"
}
```

### **1.3 Configura√ß√£o de Permiss√µes no Google Drive**

#### **Compartilhamento de Pastas**
Para cada pasta que ser√° monitorada pelo collector:

```bash
# 1. Abra o Google Drive no navegador
# 2. Localize a pasta que cont√©m os arquivos
# 3. Clique com bot√£o direito > "Compartilhar"
# 4. Adicione o email do Service Account:
#    gdrive-collector@farmarcas-data-platform.iam.gserviceaccount.com
# 5. Defina permiss√£o como "Viewer" (somente leitura)
# 6. Anote o ID da pasta (vis√≠vel na URL)
```

#### **Obten√ß√£o de IDs de Pastas e Arquivos**
```bash
# Para pasta: https://drive.google.com/drive/folders/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms
# ID da pasta: 1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms

# Para arquivo: https://docs.google.com/spreadsheets/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/edit
# ID do arquivo: 1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms
```

### **1.4 Teste de Conectividade**

Script para validar a autentica√ß√£o:

```python
#!/usr/bin/env python3
"""
Script de teste para validar autentica√ß√£o Google Drive
"""

from google.oauth2 import service_account
from googleapiclient.discovery import build
import json

def test_google_drive_auth(credentials_path):
    """
    Testa autentica√ß√£o com Google Drive API
    """
    
    try:
        # Carregar credenciais
        credentials = service_account.Credentials.from_service_account_file(
            credentials_path,
            scopes=['https://www.googleapis.com/auth/drive.readonly']
        )
        
        # Criar cliente da API
        service = build('drive', 'v3', credentials=credentials)
        
        # Testar acesso b√°sico
        about = service.about().get(fields="user").execute()
        user_email = about.get('user', {}).get('emailAddress')
        
        print(f"‚úÖ Autentica√ß√£o bem-sucedida!")
        print(f"üìß Service Account: {user_email}")
        
        # Testar listagem de arquivos (primeiros 10)
        results = service.files().list(pageSize=10).execute()
        files = results.get('files', [])
        
        print(f"üìÅ Arquivos vis√≠veis: {len(files)}")
        
        if files:
            print("üìã Primeiros arquivos encontrados:")
            for file in files[:3]:
                print(f"   - {file['name']} (ID: {file['id']})")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro na autentica√ß√£o: {str(e)}")
        return False

if __name__ == "__main__":
    credentials_path = "google_service_account.json"
    test_google_drive_auth(credentials_path)
```

---

## ‚òÅÔ∏è 2. Configura√ß√£o AWS

### **2.1 Credenciais AWS**

#### **IAM User para Desenvolvimento**
```bash
# 1. Acesse AWS Console > IAM > Users
# 2. Create User: "gdrive-collector-dev"
# 3. Attach policies directly
# 4. Create Access Key
# 5. Anote Access Key ID e Secret Access Key
```

#### **IAM Role para Produ√ß√£o (EKS/Fargate)**
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "eks-fargate-pods.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
```

### **2.2 Pol√≠ticas IAM Necess√°rias**

#### **Pol√≠tica S3 (M√≠nima)**
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "S3BronzeLayerAccess",
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:PutObjectAcl", 
        "s3:GetObject",
        "s3:DeleteObject"
      ],
      "Resource": [
        "arn:aws:s3:::farmarcas-production-bronze/origin=eks/database=bronze_gdrive/*"
      ]
    },
    {
      "Sid": "S3BucketLevelAccess",
      "Effect": "Allow",
      "Action": [
        "s3:ListBucket",
        "s3:GetBucketLocation"
      ],
      "Resource": [
        "arn:aws:s3:::farmarcas-production-bronze"
      ],
      "Condition": {
        "StringLike": {
          "s3:prefix": ["origin=eks/database=bronze_gdrive/*"]
        }
      }
    }
  ]
}
```

#### **Pol√≠tica CloudWatch Logs**
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "CloudWatchLogsAccess",
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream", 
        "logs:PutLogEvents",
        "logs:DescribeLogGroups",
        "logs:DescribeLogStreams"
      ],
      "Resource": [
        "arn:aws:logs:us-east-2:*:log-group:/aws/fargate/gdrive-collector*"
      ]
    }
  ]
}
```

#### **Pol√≠tica Glue (Opcional para Cataloga√ß√£o)**
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "GlueCatalogAccess",
      "Effect": "Allow",
      "Action": [
        "glue:GetDatabase",
        "glue:GetTable",
        "glue:CreateTable",
        "glue:UpdateTable",
        "glue:BatchCreatePartition"
      ],
      "Resource": [
        "arn:aws:glue:us-east-2:*:catalog",
        "arn:aws:glue:us-east-2:*:database/bronze_gdrive",
        "arn:aws:glue:us-east-2:*:table/bronze_gdrive/*"
      ]
    }
  ]
}
```

### **2.3 Configura√ß√£o de Credenciais**

#### **Via Vari√°veis de Ambiente**
```bash
# Desenvolvimento Local
export AWS_ACCESS_KEY_ID="AKIA..."
export AWS_SECRET_ACCESS_KEY="..."
export AWS_DEFAULT_REGION="us-east-2"
export AWS_SESSION_TOKEN=""  # Se usando STS

# Verificar configura√ß√£o
aws sts get-caller-identity
aws s3 ls farmarcas-production-bronze --prefix "origin=eks/database=bronze_gdrive/"
```

#### **Via AWS Credentials File**
```ini
# ~/.aws/credentials
[gdrive-collector]
aws_access_key_id = AKIA...
aws_secret_access_key = ...
region = us-east-2

# ~/.aws/config  
[profile gdrive-collector]
region = us-east-2
output = json
```

#### **Via IAM Role (Produ√ß√£o)**
```yaml
# EKS Service Account
apiVersion: v1
kind: ServiceAccount
metadata:
  name: gdrive-collector
  namespace: data-platform
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/gdrive-collector-role
```

### **2.4 Teste de Conectividade AWS**

```python
#!/usr/bin/env python3
"""
Script de teste para validar acesso AWS
"""

import boto3
import json
from datetime import datetime

def test_aws_access():
    """
    Testa acesso aos servi√ßos AWS necess√°rios
    """
    
    try:
        # Teste STS (identidade)
        sts = boto3.client('sts')
        identity = sts.get_caller_identity()
        
        print(f"‚úÖ AWS Autentica√ß√£o bem-sucedida!")
        print(f"üë§ Account: {identity['Account']}")
        print(f"üÜî User/Role: {identity['Arn']}")
        
        # Teste S3
        s3 = boto3.client('s3')
        bucket_name = "farmarcas-production-bronze"
        prefix = "origin=eks/database=bronze_gdrive/"
        
        # Testar listagem
        response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix, MaxKeys=5)
        object_count = response.get('KeyCount', 0)
        
        print(f"üì¶ S3 Bucket: {bucket_name}")
        print(f"üìÅ Objetos no prefixo: {object_count}")
        
        # Testar upload
        test_key = f"{prefix}test/{datetime.now().isoformat()}.txt"
        s3.put_object(
            Bucket=bucket_name,
            Key=test_key,
            Body=b"Test upload from gdrive-collector",
            Metadata={'source': 'test'}
        )
        
        print(f"‚úÖ Upload teste bem-sucedido: {test_key}")
        
        # Limpar arquivo teste
        s3.delete_object(Bucket=bucket_name, Key=test_key)
        print(f"üóëÔ∏è Arquivo teste removido")
        
        # Teste CloudWatch Logs (opcional)
        try:
            logs = boto3.client('logs')
            log_groups = logs.describe_log_groups(logGroupNamePrefix='/aws/fargate/gdrive')
            print(f"üìä CloudWatch Log Groups: {len(log_groups['logGroups'])}")
        except Exception as e:
            print(f"‚ö†Ô∏è CloudWatch Logs: {str(e)}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro AWS: {str(e)}")
        return False

if __name__ == "__main__":
    test_aws_access()
```

---

## üêç 3. Depend√™ncias Python

### **3.1 requirements.txt**

```txt
# Google APIs
google-auth==2.17.3
google-auth-oauthlib==1.0.0
google-auth-httplib2==0.1.0
google-api-python-client==2.88.0

# AWS Services
boto3==1.26.137
awswrangler==3.2.0

# Data Processing
pandas==2.0.2
openpyxl==3.1.2           # Excel reading
xlrd==2.0.1               # Legacy Excel support

# Utilities
PyYAML==6.0
pytz==2023.3
python-dateutil==2.8.2

# Logging and Monitoring
structlog==23.1.0
psutil==5.9.5             # System monitoring

# Development/Testing (optional)
pytest==7.3.1
pytest-cov==4.1.0
black==23.3.0
flake8==6.0.0
```

### **3.2 Instala√ß√£o do Ambiente**

#### **Via pip (Desenvolvimento)**
```bash
# Criar ambiente virtual
python3 -m venv venv
source venv/bin/activate  # Linux/macOS
# ou
venv\Scripts\activate     # Windows

# Instalar depend√™ncias
pip install --upgrade pip
pip install -r requirements.txt

# Verificar instala√ß√£o
pip list | grep -E "(google|boto3|pandas|awswrangler)"
```

#### **Via conda (Alternativo)**
```bash
# Criar ambiente conda
conda create -n gdrive-collector python=3.9
conda activate gdrive-collector

# Instalar principais depend√™ncias via conda
conda install pandas openpyxl xlrd pyyaml boto3

# Instalar Google APIs via pip
pip install google-auth google-api-python-client awswrangler
```

#### **Dockerfile para Produ√ß√£o**
```dockerfile
FROM python:3.9-slim

# Instalar depend√™ncias do sistema
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copiar e instalar requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copiar c√≥digo da aplica√ß√£o
COPY collector_gdrive/ ./collector_gdrive/
COPY files_configs.yaml .

# Configurar usu√°rio n√£o-root
RUN useradd -m -u 1000 collector
USER collector

# Definir ponto de entrada
ENTRYPOINT ["python", "collector_gdrive/main.py"]
```

### **3.3 Valida√ß√£o das Depend√™ncias**

```python
#!/usr/bin/env python3
"""
Script para validar todas as depend√™ncias necess√°rias
"""

import sys
import importlib

def check_dependencies():
    """
    Verifica se todas as depend√™ncias est√£o instaladas
    """
    
    required_packages = {
        # Google APIs
        'google.auth': 'google-auth',
        'google.oauth2': 'google-auth', 
        'googleapiclient.discovery': 'google-api-python-client',
        
        # AWS
        'boto3': 'boto3',
        'awswrangler': 'awswrangler',
        
        # Data Processing
        'pandas': 'pandas',
        'openpyxl': 'openpyxl',
        'xlrd': 'xlrd',
        
        # Utilities
        'yaml': 'PyYAML',
        'pytz': 'pytz',
        'dateutil': 'python-dateutil',
    }
    
    print("üîç Verificando depend√™ncias...")
    
    missing_packages = []
    
    for module_name, package_name in required_packages.items():
        try:
            importlib.import_module(module_name)
            print(f"‚úÖ {package_name}")
        except ImportError:
            print(f"‚ùå {package_name}")
            missing_packages.append(package_name)
    
    if missing_packages:
        print(f"\n‚ö†Ô∏è Pacotes ausentes: {', '.join(missing_packages)}")
        print("üí° Execute: pip install " + " ".join(missing_packages))
        return False
    
    print("\n‚úÖ Todas as depend√™ncias est√£o instaladas!")
    
    # Verificar vers√µes cr√≠ticas
    print("\nüìã Vers√µes das depend√™ncias principais:")
    
    try:
        import pandas as pd
        print(f"   pandas: {pd.__version__}")
    except:
        pass
        
    try:
        import boto3
        print(f"   boto3: {boto3.__version__}")
    except:
        pass
        
    try:
        import awswrangler as wr
        print(f"   awswrangler: {wr.__version__}")
    except:
        pass
    
    return True

if __name__ == "__main__":
    success = check_dependencies()
    sys.exit(0 if success else 1)
```

---

## üîß 4. Vari√°veis de Ambiente

### **4.1 Vari√°veis Obrigat√≥rias**

```bash
# Google Drive Authentication
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/google_service_account.json"

# AWS Configuration
export AWS_ACCESS_KEY_ID="AKIA..."
export AWS_SECRET_ACCESS_KEY="..."
export AWS_DEFAULT_REGION="us-east-2"

# Application Configuration
export S3_BUCKET_NAME="farmarcas-production-bronze"
export LOG_LEVEL="INFO"
export ENVIRONMENT="production"
```

### **4.2 Vari√°veis Opcionais**

```bash
# Performance Tuning
export MAX_CONCURRENT_DOWNLOADS="5"
export DOWNLOAD_CHUNK_SIZE_MB="10"
export API_RATE_LIMIT="10"

# Monitoring and Alerts
export SLACK_WEBHOOK_URL="https://hooks.slack.com/services/..."
export CLOUDWATCH_LOG_GROUP="/aws/fargate/gdrive-collector"

# Development/Debug
export DEBUG_MODE="false"
export CACHE_ENABLED="true"
export CACHE_DIR="/tmp/gdrive_cache"

# Timezone
export TZ="America/Sao_Paulo"
```

### **4.3 Arquivo .env para Desenvolvimento**

```bash
# .env file (para desenvolvimento local)
# N√ÉO COMMITAR ESTE ARQUIVO

# Google Drive
GOOGLE_APPLICATION_CREDENTIALS=./credentials/google_service_account.json

# AWS
AWS_ACCESS_KEY_ID=AKIA...
AWS_SECRET_ACCESS_KEY=...
AWS_DEFAULT_REGION=us-east-2

# Application
S3_BUCKET_NAME=farmarcas-development-bronze
LOG_LEVEL=DEBUG
ENVIRONMENT=development

# Optional
DEBUG_MODE=true
CACHE_ENABLED=false
MAX_CONCURRENT_DOWNLOADS=3
```

### **4.4 Configura√ß√£o Docker/Kubernetes**

```yaml
# docker-compose.yml (desenvolvimento)
version: '3.8'
services:
  gdrive-collector:
    build: .
    environment:
      - GOOGLE_APPLICATION_CREDENTIALS=/app/credentials/google_service_account.json
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=us-east-2
      - S3_BUCKET_NAME=farmarcas-development-bronze
      - LOG_LEVEL=INFO
    volumes:
      - ./credentials:/app/credentials:ro
    networks:
      - data-platform

# kubernetes-deployment.yaml (produ√ß√£o)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gdrive-collector
spec:
  template:
    spec:
      serviceAccountName: gdrive-collector  # Com IAM Role
      containers:
      - name: collector
        image: farmarcas/gdrive-collector:latest
        env:
        - name: GOOGLE_APPLICATION_CREDENTIALS
          value: /app/credentials/google_service_account.json
        - name: S3_BUCKET_NAME
          value: farmarcas-production-bronze
        - name: LOG_LEVEL
          value: INFO
        - name: ENVIRONMENT
          value: production
        volumeMounts:
        - name: google-credentials
          mountPath: /app/credentials
          readOnly: true
      volumes:
      - name: google-credentials
        secret:
          secretName: google-service-account
```

---

## üåê 5. Configura√ß√£o de Rede

### **5.1 Firewall e Conectividade**

#### **URLs que Precisam de Acesso**
```bash
# Google APIs
https://www.googleapis.com          # Google Drive API
https://accounts.google.com         # OAuth2 authentication
https://oauth2.googleapis.com       # Token refresh

# AWS Services
https://s3.us-east-2.amazonaws.com  # S3 operations
https://logs.us-east-2.amazonaws.com # CloudWatch Logs
https://sts.amazonaws.com           # Identity verification

# Portas necess√°rias
443/tcp  # HTTPS para todas as APIs
53/tcp   # DNS resolution
53/udp   # DNS resolution
```

#### **Configura√ß√£o Proxy (se necess√°rio)**
```bash
# Via vari√°veis de ambiente
export HTTP_PROXY="http://proxy.company.com:8080"
export HTTPS_PROXY="http://proxy.company.com:8080"
export NO_PROXY="localhost,127.0.0.1,.internal.domain"

# Via pip (para instala√ß√£o de depend√™ncias)
pip install --proxy http://proxy.company.com:8080 -r requirements.txt
```

### **5.2 Seguran√ßa**

#### **TLS/SSL Verification**
```python
import ssl
import urllib3

# Para ambientes corporativos com certificados pr√≥prios
# APENAS SE ABSOLUTAMENTE NECESS√ÅRIO
def configure_ssl_context():
    """
    Configura√ß√£o SSL para ambientes corporativos
    """
    
    # Op√ß√£o 1: Usar certificados customizados
    ssl_context = ssl.create_default_context()
    ssl_context.load_verify_locations('/path/to/corporate-ca.pem')
    
    # Op√ß√£o 2: Desabilitar verifica√ß√£o (N√ÉO RECOMENDADO)
    # ssl_context.check_hostname = False
    # ssl_context.verify_mode = ssl.CERT_NONE
    # urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    
    return ssl_context
```

---

## ‚úÖ 6. Checklist de Valida√ß√£o

### **6.1 Google Drive API**
```bash
‚úÖ Projeto criado no Google Cloud Console
‚úÖ Google Drive API habilitada
‚úÖ Service Account criado
‚úÖ Arquivo JSON de credenciais baixado
‚úÖ Pastas compartilhadas com Service Account
‚úÖ IDs de pastas/arquivos coletados
‚úÖ Teste de conectividade executado com sucesso
```

### **6.2 AWS**
```bash
‚úÖ IAM User/Role configurado
‚úÖ Pol√≠ticas S3 anexadas
‚úÖ Pol√≠ticas CloudWatch Logs anexadas
‚úÖ Credenciais AWS configuradas
‚úÖ Acesso ao bucket S3 validado
‚úÖ Teste de upload/download S3 executado
```

### **6.3 Python Environment**
```bash
‚úÖ Python 3.9+ instalado
‚úÖ Ambiente virtual criado
‚úÖ requirements.txt instalado
‚úÖ Todas as depend√™ncias validadas
‚úÖ Teste de importa√ß√£o executado
```

### **6.4 Configura√ß√µes**
```bash
‚úÖ Vari√°veis de ambiente definidas
‚úÖ files_configs.yaml configurado
‚úÖ Credenciais Google Drive no local correto
‚úÖ Logs de teste executados com sucesso
‚úÖ Conectividade de rede validada
```

### **6.5 Script de Valida√ß√£o Completa**

```python
#!/usr/bin/env python3
"""
Script completo de valida√ß√£o de pr√©-requisitos
"""

import os
import sys
import json
from pathlib import Path

def validate_environment():
    """
    Executa valida√ß√£o completa do ambiente
    """
    
    print("üîç Iniciando valida√ß√£o completa do ambiente...")
    
    checks = []
    
    # 1. Vari√°veis de ambiente
    required_env_vars = [
        'GOOGLE_APPLICATION_CREDENTIALS',
        'AWS_ACCESS_KEY_ID', 
        'AWS_SECRET_ACCESS_KEY',
        'AWS_DEFAULT_REGION'
    ]
    
    for var in required_env_vars:
        if os.getenv(var):
            print(f"‚úÖ {var}")
            checks.append(True)
        else:
            print(f"‚ùå {var} n√£o definida")
            checks.append(False)
    
    # 2. Arquivo de credenciais Google
    google_creds = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')
    if google_creds and Path(google_creds).exists():
        try:
            with open(google_creds) as f:
                creds_data = json.load(f)
                if 'client_email' in creds_data:
                    print(f"‚úÖ Credenciais Google: {creds_data['client_email']}")
                    checks.append(True)
                else:
                    print("‚ùå Arquivo de credenciais Google inv√°lido")
                    checks.append(False)
        except Exception as e:
            print(f"‚ùå Erro ao ler credenciais Google: {e}")
            checks.append(False)
    else:
        print("‚ùå Arquivo de credenciais Google n√£o encontrado")
        checks.append(False)
    
    # 3. Depend√™ncias Python
    try:
        import google.auth
        import boto3
        import pandas as pd
        import awswrangler as wr
        print("‚úÖ Depend√™ncias Python instaladas")
        checks.append(True)
    except ImportError as e:
        print(f"‚ùå Depend√™ncias Python ausentes: {e}")
        checks.append(False)
    
    # 4. Conectividade (testes b√°sicos)
    try:
        # Teste Google Drive
        from google.oauth2 import service_account
        from googleapiclient.discovery import build
        
        credentials = service_account.Credentials.from_service_account_file(
            google_creds,
            scopes=['https://www.googleapis.com/auth/drive.readonly']
        )
        service = build('drive', 'v3', credentials=credentials)
        service.about().get(fields="user").execute()
        
        print("‚úÖ Conectividade Google Drive")
        checks.append(True)
    except Exception as e:
        print(f"‚ùå Conectividade Google Drive: {e}")
        checks.append(False)
    
    try:
        # Teste AWS
        import boto3
        sts = boto3.client('sts')
        sts.get_caller_identity()
        
        print("‚úÖ Conectividade AWS")
        checks.append(True)
    except Exception as e:
        print(f"‚ùå Conectividade AWS: {e}")
        checks.append(False)
    
    # Resultado final
    success_rate = sum(checks) / len(checks) * 100
    
    print(f"\nüìä Resultado: {success_rate:.1f}% dos checks aprovados")
    
    if success_rate == 100:
        print("üéâ Ambiente completamente configurado!")
        return True
    elif success_rate >= 80:
        print("‚ö†Ô∏è Ambiente quase pronto - verifique itens pendentes")
        return True
    else:
        print("‚ùå Ambiente precisa de configura√ß√£o adicional")
        return False

if __name__ == "__main__":
    success = validate_environment()
    sys.exit(0 if success else 1)
```

---

**√öltima Atualiza√ß√£o**: 07/08/2025 - Pr√©-requisitos validados para ambiente de produ√ß√£o
