# üìÑ files_configs.yaml - Configura√ß√£o do Google Drive Collector

## üìã Vis√£o Geral

O arquivo `files_configs.yaml` √© o cora√ß√£o da configura√ß√£o do Google Drive Collector, definindo quais arquivos e pastas devem ser coletados, como devem ser processados e onde devem ser armazenados no data lake.

### **Estrutura Hier√°rquica**
```mermaid
graph TD
    A[files_configs.yaml] --> B[Configura√ß√µes Individuais]
    A --> C[Configura√ß√µes de Pastas]
    
    B --> D[gdrive_file_id]
    B --> E[table_name] 
    B --> F[datalake config]
    B --> G[schema opcional]
    
    C --> H[gdrive_folder_id]
    C --> I[table_name]
    C --> J[datalake config]
    C --> K[processamento batch]
    
    style A fill:#e1f5fe
    style B fill:#e8f5e8
    style C fill:#fff3e0
```

---

## üóÇÔ∏è Estrutura Completa do Arquivo

### **Arquivo files_configs.yaml Real (Produ√ß√£o)**

```yaml
# ===============================================
# CONFIGURA√á√ÉO GOOGLE DRIVE COLLECTOR - FARMARCAS
# ===============================================

# üìã ARQUIVO: Base de Produtos
# Dados centrais do cat√°logo farmac√™utico
base:
  name: "Base de Produtos"
  gdrive_file_id: "1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms"
  table_name: "base"
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"

# üè™ ARQUIVO: Cadastro de Lojas
# Rede de farm√°cias e pontos de venda
loja:
  name: "Cadastro de Lojas"
  gdrive_file_id: "1hsJJT5SVaE8bNcBGFstO7f0Lh8v8QnHG8v7f9G2mF4"
  table_name: "loja"
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"

# üöö ARQUIVO: Distribuidores
# Informa√ß√µes de distribuidores e canais
distribuidor:
  name: "Distribuidores"
  gdrive_file_id: "1mGQR7gH8vK3PlxY9N0sE2uZ6xW4qR8mF9N2sE3uZ7"
  table_name: "distribuidor"
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"

# üí∞ ARQUIVO: Verbas Dashboard
# Dados financeiros de verbas e incentivos
verbas_base_industria:
  name: "Verbas Dashboard"
  gdrive_file_id: "1qR2sT4uV5wX6yZ7aB8cD9eF0gH1iJ2kL3mN4oP5qR6"
  table_name: "verbas_base_industria"
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"

# üìÇ PASTA: Rebates Template
# M√∫ltiplos arquivos de rebates de laborat√≥rios
rebates_template:
  name: "rebates_template"
  gdrive_folder_id: "1_4xO-dsMBrCOcr8uNdFHFhrmP7Lh2Y8_"
  table_name: "rebates_template"
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"

# üìç ARQUIVO: Geografia
# Divis√µes territoriais e hierarquias regionais
geografia:
  name: "Geografia"
  gdrive_file_id: "1sT3uV4wX5yZ6aB7cD8eF9gH0iJ1kL2mN3oP4qR5sT6"
  table_name: "geografia"
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"

# üìä ARQUIVO: Al√≠quotas ICMS
# Dados fiscais por estado e produto
aliquota_icms:
  name: "Al√≠quotas ICMS"
  gdrive_file_id: "1uV2wX3yZ4aB5cD6eF7gH8iJ9kL0mN1oP2qR3sT4uV5"
  table_name: "aliquota_icms"
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"
```

---

## üîß Componentes de Configura√ß√£o

### **1. Configura√ß√£o de Arquivo Individual**

#### **Estrutura B√°sica**
```yaml
nome_da_configuracao:
  name: "Nome Descritivo do Arquivo"
  gdrive_file_id: "ID_DO_ARQUIVO_NO_GOOGLE_DRIVE"
  table_name: "nome_tabela_destino"
  datalake:
    bucket: "bucket-s3-destino"
    database: "database-glue-catalog"
```

#### **Exemplo Detalhado**
```yaml
base_produtos_completa:
  # Identifica√ß√£o e descri√ß√£o
  name: "Base Completa de Produtos Farmac√™uticos"
  
  # ID √∫nico do arquivo no Google Drive
  # Extra√≠do da URL: https://docs.google.com/spreadsheets/d/1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms/edit
  gdrive_file_id: "1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms"
  
  # Nome da tabela no data lake (usado para S3 key e Glue)
  table_name: "base_produtos"
  
  # Configura√ß√£o do destino no data lake
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"
    
  # Configura√ß√£o opcional de schema
  schema:
    # Renomea√ß√£o de colunas se necess√°rio
    column_mapping:
      "C√≥digo EAN": "ean_codigo"
      "Nome Produto": "produto_nome"
      "Laborat√≥rio": "laboratorio_nome"
      "NCM": "ncm_codigo"
      "Pre√ßo PMC": "preco_pmc"
    
    # Convers√£o de tipos de dados
    types:
      ean_codigo: "string"
      preco_pmc: "numeric"
      data_lancamento: "datetime"
    
    # Valida√ß√µes de qualidade
    validation:
      min_rows: 1000  # M√≠nimo 1000 produtos
      required_columns: ["ean_codigo", "produto_nome", "laboratorio_nome"]
      
  # Configura√ß√µes de processamento
  processing:
    # Remover linhas vazias
    drop_empty_rows: true
    # Remover colunas completamente vazias
    drop_empty_columns: true
    # Aplicar limpeza de strings
    clean_strings: true
```

### **2. Configura√ß√£o de Pasta (M√∫ltiplos Arquivos)**

#### **Estrutura B√°sica**
```yaml
nome_da_pasta:
  name: "Nome Descritivo da Pasta"
  gdrive_folder_id: "ID_DA_PASTA_NO_GOOGLE_DRIVE"
  table_name: "nome_tabela_consolidada"
  datalake:
    bucket: "bucket-s3-destino"
    database: "database-glue-catalog"
```

#### **Exemplo: Pasta Rebates**
```yaml
rebates_laboratorios:
  # Identifica√ß√£o
  name: "Rebates de Laborat√≥rios"
  
  # ID da pasta no Google Drive
  # Extra√≠do da URL: https://drive.google.com/drive/folders/1_4xO-dsMBrCOcr8uNdFHFhrmP7Lh2Y8_
  gdrive_folder_id: "1_4xO-dsMBrCOcr8uNdFHFhrmP7Lh2Y8_"
  
  # Tabela consolidada (todos os arquivos da pasta)
  table_name: "rebates_consolidado"
  
  # Destino no data lake
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"
  
  # Configura√ß√£o de processamento de pasta
  folder_processing:
    # Filtros de arquivo
    file_filters:
      extensions: [".xlsx", ".xls"]  # Apenas Excel
      exclude_patterns: ["*temp*", "*backup*", "*~*"]  # Excluir tempor√°rios
      min_size_kb: 10  # M√≠nimo 10KB
      max_size_mb: 50  # M√°ximo 50MB
    
    # Consolida√ß√£o
    consolidation:
      method: "union"  # union, concat, merge
      add_source_column: true  # Adiciona coluna com nome do arquivo
      source_column_name: "arquivo_origem"
    
    # Schema comum para todos os arquivos
    schema:
      column_mapping:
        "Lab": "laboratorio"
        "Produto": "produto"
        "Verba": "valor_verba"
        "Data": "data_competencia"
      
      types:
        valor_verba: "numeric"
        data_competencia: "datetime"
        
      validation:
        min_rows: 50  # Cada arquivo deve ter pelo menos 50 linhas
        required_columns: ["laboratorio", "produto", "valor_verba"]
```

### **3. Configura√ß√£o com M√∫ltiplas Abas**

```yaml
relatorio_vendas_completo:
  name: "Relat√≥rio de Vendas Mensal Completo"
  gdrive_file_id: "1234567890abcdef1234567890abcdef12345678"
  
  # Configura√ß√£o por aba do Excel
  sheets:
    # Aba 1: Vendas por Produto
    vendas_produto:
      table_name: "vendas_produto_mensal"
      sheet_name: "Vendas Produto"  # Nome exato da aba
      
      schema:
        column_mapping:
          "C√≥d. EAN": "ean"
          "Qtd Vendida": "quantidade"
          "Valor Total": "valor_vendas"
        
        types:
          quantidade: "numeric"
          valor_vendas: "numeric"
          
      validation:
        min_rows: 100
        required_columns: ["ean", "quantidade", "valor_vendas"]
    
    # Aba 2: Vendas por Regi√£o
    vendas_regiao:
      table_name: "vendas_regiao_mensal"
      sheet_name: "Vendas Regi√£o"
      
      schema:
        column_mapping:
          "Regi√£o": "regiao_nome"
          "Estado": "estado_uf"
          "Vendas": "valor_vendas"
        
        types:
          valor_vendas: "numeric"
          
      validation:
        min_rows: 27  # 26 estados + DF
        required_columns: ["regiao_nome", "estado_uf", "valor_vendas"]
  
  # Configura√ß√£o geral do data lake
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"
```

---

## üìä Schemas e Transforma√ß√µes

### **1. Mapeamento de Colunas**

#### **Exemplos Comuns**
```yaml
schema:
  column_mapping:
    # Padroniza√ß√£o de nomes
    "C√ìDIGO EAN": "ean_codigo"
    "NOME DO PRODUTO": "produto_nome"
    "LABORAT√ìRIO": "laboratorio_nome"
    
    # Remo√ß√£o de caracteres especiais
    "Pre√ßo (R$)": "preco_reais"
    "Data/Hora": "data_hora"
    "Status (Ativo/Inativo)": "status"
    
    # Padroniza√ß√£o de idioma
    "Name": "nome"
    "Description": "descricao"
    "Category": "categoria"
    
    # Tratamento de abrevia√ß√µes
    "Qtd": "quantidade"
    "Vlr": "valor"
    "Dt": "data"
```

#### **Regras de Nomenclatura**
```yaml
# PADR√ïES ADOTADOS:
# - snake_case para nomes de colunas
# - Sem caracteres especiais (acentos, s√≠mbolos)
# - Nomes descritivos e consistentes
# - Prefixos por contexto quando necess√°rio

exemplos_nomenclatura:
  # Datas
  "data_competencia"     # ao inv√©s de "Data"
  "data_vencimento"      # ao inv√©s de "Vencto"
  "data_nascimento"      # ao inv√©s de "Dt Nasc"
  
  # Valores monet√°rios
  "valor_unitario"       # ao inv√©s de "Vlr Unit"
  "preco_pmc"           # ao inv√©s de "PMC"
  "valor_desconto"      # ao inv√©s de "Desc (%)"
  
  # C√≥digos e identificadores
  "cnpj_numero"         # ao inv√©s de "CNPJ"
  "ean_codigo"          # ao inv√©s de "EAN"
  "ncm_codigo"          # ao inv√©s de "NCM"
  
  # Status e flags
  "status_ativo"        # ao inv√©s de "Ativo?"
  "flag_promocao"       # ao inv√©s de "Promo√ß√£o"
  "indicador_novo"      # ao inv√©s de "Novo Produto"
```

### **2. Convers√£o de Tipos**

#### **Tipos Suportados**
```yaml
schema:
  types:
    # Strings (texto)
    produto_nome: "string"
    laboratorio_nome: "string"
    
    # Num√©ricos
    quantidade: "numeric"
    preco_unitario: "numeric"
    percentual_desconto: "numeric"
    
    # Datas e timestamps
    data_competencia: "datetime"
    timestamp_processamento: "datetime"
    
    # Booleanos
    ativo: "boolean"
    promocao: "boolean"
    
    # Categoriais (mantidos como string)
    regiao: "string"
    categoria_produto: "string"
```

#### **Tratamento de Erros de Convers√£o**
```yaml
schema:
  types:
    # Convers√£o num√©rica com fallback
    preco_unitario: 
      type: "numeric"
      errors: "coerce"  # Valores inv√°lidos viram NaN
      fill_na: 0        # Substituir NaN por 0
    
    # Convers√£o de data com formato espec√≠fico
    data_competencia:
      type: "datetime"
      format: "%d/%m/%Y"  # Formato brasileiro
      errors: "coerce"
      
    # Convers√£o booleana com mapeamento
    ativo:
      type: "boolean"
      mapping:
        "S": true
        "N": false
        "Sim": true
        "N√£o": false
        "1": true
        "0": false
```

### **3. Valida√ß√µes de Qualidade**

#### **Valida√ß√µes B√°sicas**
```yaml
schema:
  validation:
    # Quantidade m√≠nima de registros
    min_rows: 100
    max_rows: 1000000
    
    # Colunas obrigat√≥rias
    required_columns: 
      - "ean_codigo"
      - "produto_nome"
      - "laboratorio_nome"
    
    # Valores √∫nicos (chaves prim√°rias)
    unique_columns:
      - "ean_codigo"
    
    # Valores n√£o nulos
    not_null_columns:
      - "ean_codigo"
      - "produto_nome"
      - "preco_unitario"
```

#### **Valida√ß√µes Avan√ßadas**
```yaml
schema:
  validation:
    # Valida√ß√µes de formato
    format_checks:
      ean_codigo:
        pattern: "^[0-9]{13}$"  # EAN-13 obrigat√≥rio
        message: "EAN deve ter exatamente 13 d√≠gitos"
      
      cnpj_numero:
        pattern: "^[0-9]{14}$"  # CNPJ sem formata√ß√£o
        message: "CNPJ deve ter 14 d√≠gitos"
    
    # Valida√ß√µes de intervalo
    range_checks:
      preco_unitario:
        min: 0.01
        max: 10000.00
        message: "Pre√ßo deve estar entre R$ 0,01 e R$ 10.000,00"
      
      quantidade:
        min: 0
        max: 999999
        message: "Quantidade deve ser positiva"
    
    # Valida√ß√µes de valores permitidos
    allowed_values:
      status:
        values: ["ATIVO", "INATIVO", "DESCONTINUADO"]
        message: "Status deve ser ATIVO, INATIVO ou DESCONTINUADO"
      
      regiao:
        values: ["NORTE", "NORDESTE", "CENTRO-OESTE", "SUDESTE", "SUL"]
        message: "Regi√£o deve ser uma das 5 regi√µes brasileiras"
```

---

## üóÑÔ∏è Configura√ß√£o do Data Lake

### **1. Estrutura S3**

#### **Padr√£o de Chaves S3**
```yaml
# Padr√£o adotado:
# s3://bucket/origin=origem/database=database/table_name/cog_dt_ingestion=YYYY-MM-DD/file.parquet

datalake:
  bucket: "farmarcas-production-bronze"
  database: "bronze_gdrive"
  
# Resultado para tabela "base":
# s3://farmarcas-production-bronze/origin=eks/database=bronze_gdrive/base/cog_dt_ingestion=2025-08-07/base.parquet
```

#### **Configura√ß√µes de Bucket**
```yaml
datalake:
  # Bucket principal
  bucket: "farmarcas-production-bronze"
  
  # Database no AWS Glue Catalog
  database: "bronze_gdrive"
  
  # Configura√ß√µes de particionamento
  partitioning:
    columns: ["cog_dt_ingestion"]  # Particionar por data de ingest√£o
    format: "YYYY-MM-DD"           # Formato da parti√ß√£o
  
  # Configura√ß√µes de compress√£o
  compression: "snappy"            # snappy, gzip, brotli
  
  # Configura√ß√µes de formato
  format: "parquet"                # parquet, csv, json
  
  # Configura√ß√µes de metadados
  metadata:
    add_ingestion_timestamp: true
    add_source_info: true
    add_schema_version: true
```

### **2. Integra√ß√£o com AWS Glue**

#### **Catalog Configuration**
```yaml
datalake:
  bucket: "farmarcas-production-bronze"
  database: "bronze_gdrive"
  
  # Configura√ß√£o AWS Glue
  glue_catalog:
    # Atualizar cat√°logo automaticamente
    auto_create_table: true
    auto_update_schema: true
    
    # Configura√ß√µes da tabela
    table_properties:
      "classification": "parquet"
      "compressionType": "snappy"
      "typeOfData": "file"
      "sourceSystem": "google-drive"
      
    # Configura√ß√µes de storage
    storage_descriptor:
      input_format: "org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat"
      output_format: "org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat"
      serde_info:
        serialization_library: "org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe"
```

### **3. Configura√ß√µes de Backup**

```yaml
datalake:
  bucket: "farmarcas-production-bronze"
  database: "bronze_gdrive"
  
  # Configura√ß√£o de backup
  backup:
    enabled: true
    backup_bucket: "farmarcas-backup-gdrive"
    retention_days: 90
    
    # Replica√ß√£o cross-region
    cross_region_replication:
      enabled: true
      destination_region: "us-west-2"
      destination_bucket: "farmarcas-backup-gdrive-west"
    
    # Versionamento
    versioning:
      enabled: true
      max_versions: 5
```

---

## üîÑ Configura√ß√µes de Processamento

### **1. Performance e Otimiza√ß√£o**

```yaml
# Configura√ß√µes globais de performance
performance:
  # Download settings
  max_concurrent_downloads: 5
  download_chunk_size_mb: 10
  download_timeout_seconds: 300
  
  # Processing settings
  pandas_chunksize: 10000        # Processar DataFrames em chunks
  max_memory_usage_mb: 1024      # Limite de mem√≥ria por processo
  
  # AWS settings
  s3_multipart_threshold_mb: 100 # Usar multipart upload para arquivos > 100MB
  s3_max_concurrency: 5          # M√°ximo 5 uploads simult√¢neos
  
  # Retry settings
  max_retries: 3
  retry_delay_seconds: 5
  exponential_backoff: true

# Aplicar a configura√ß√µes espec√≠ficas
base:
  name: "Base de Produtos"
  gdrive_file_id: "1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms"
  table_name: "base"
  
  # Configura√ß√µes espec√≠ficas de processamento
  processing:
    # Otimiza√ß√£o para arquivo grande
    chunk_processing: true
    chunk_size: 5000
    
    # Limpeza espec√≠fica
    data_cleaning:
      remove_duplicates: true
      duplicate_columns: ["ean_codigo"]
      
      trim_strings: true
      normalize_case: "upper"  # upper, lower, title
      
      replace_values:
        "N/A": null
        "": null
        "-": null
  
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"
```

### **2. Monitoramento e Logs**

```yaml
# Configura√ß√µes de monitoramento
monitoring:
  # CloudWatch Logs
  cloudwatch:
    log_group: "/aws/fargate/gdrive-collector"
    log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR
    
    # M√©tricas customizadas
    custom_metrics:
      - name: "FilesProcessed"
        unit: "Count"
      - name: "ProcessingTimeSeconds" 
        unit: "Seconds"
      - name: "DataSizeBytes"
        unit: "Bytes"
  
  # Alertas
  alerts:
    slack:
      webhook_url: "${SLACK_WEBHOOK_URL}"
      channel: "#data-platform"
      notify_on_success: false
      notify_on_error: true
      
    email:
      smtp_server: "smtp.company.com"
      recipients: ["data-team@farmarcas.com"]
      notify_on_error: true

# Aplicar a configura√ß√µes espec√≠ficas
base:
  name: "Base de Produtos"
  gdrive_file_id: "1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms"
  table_name: "base"
  
  # Monitoramento espec√≠fico
  monitoring:
    # Alertas espec√≠ficos para base de produtos
    quality_checks:
      min_products: 10000       # Alerta se < 10k produtos
      max_price_variation: 0.5  # Alerta se pre√ßo m√©dio variar > 50%
      required_labs: ["EUROFARMA", "EMS", "MEDLEY"]  # Laborat√≥rios obrigat√≥rios
  
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"
```

---

## üìã Exemplos de Configura√ß√µes Completas

### **1. Arquivo Simples (Base de Produtos)**

```yaml
base:
  # Identifica√ß√£o
  name: "Base de Produtos Farmarcas"
  gdrive_file_id: "1BxiMVs0XRA5nFMdKvBdBZjgmUUqptlbs74OgvE2upms"
  table_name: "base"
  
  # Schema e transforma√ß√µes
  schema:
    column_mapping:
      "C√ìDIGO EAN": "ean_codigo"
      "NOME PRODUTO": "produto_nome"
      "LABORAT√ìRIO": "laboratorio_nome"
      "NCM": "ncm_codigo"
      "PMC": "preco_pmc"
      "PF": "preco_farmacia"
      "CATEGORIA": "categoria_produto"
      "STATUS": "status_produto"
    
    types:
      ean_codigo: "string"
      preco_pmc: "numeric"
      preco_farmacia: "numeric"
      ncm_codigo: "string"
      status_produto: "string"
    
    validation:
      min_rows: 5000
      required_columns: ["ean_codigo", "produto_nome", "laboratorio_nome"]
      unique_columns: ["ean_codigo"]
      
      format_checks:
        ean_codigo:
          pattern: "^[0-9]{13}$"
          message: "EAN deve ter 13 d√≠gitos"
      
      range_checks:
        preco_pmc:
          min: 0.01
          max: 5000.00
          message: "PMC deve estar entre R$ 0,01 e R$ 5.000,00"
  
  # Processamento
  processing:
    data_cleaning:
      remove_duplicates: true
      duplicate_columns: ["ean_codigo"]
      trim_strings: true
      normalize_case: "upper"
  
  # Destino
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"
```

### **2. Pasta Complexa (Rebates)**

```yaml
rebates_template:
  # Identifica√ß√£o
  name: "Rebates de Laborat√≥rios"
  gdrive_folder_id: "1_4xO-dsMBrCOcr8uNdFHFhrmP7Lh2Y8_"
  table_name: "rebates_template"
  
  # Processamento de pasta
  folder_processing:
    file_filters:
      extensions: [".xlsx", ".xls"]
      exclude_patterns: ["*temp*", "*backup*", "*~*", ".*"]
      min_size_kb: 5
      max_size_mb: 20
      modified_since_days: 30  # Apenas arquivos dos √∫ltimos 30 dias
    
    consolidation:
      method: "union"  # Empilhar todos os arquivos
      add_source_column: true
      source_column_name: "arquivo_origem"
      
      # Padroniza√ß√£o de headers entre arquivos
      standardize_headers: true
      header_mapping:
        "Lab": "laboratorio"
        "Laborat√≥rio": "laboratorio"
        "Laboratory": "laboratorio"
        
        "Produto": "produto"
        "Product": "produto"
        "Item": "produto"
        
        "Verba": "valor_verba"
        "Rebate": "valor_verba"
        "Value": "valor_verba"
  
  # Schema consolidado
  schema:
    column_mapping:
      "laboratorio": "laboratorio_nome"
      "produto": "produto_nome"
      "valor_verba": "valor_verba_reais"
      "data": "data_competencia"
      "arquivo_origem": "arquivo_fonte"
    
    types:
      laboratorio_nome: "string"
      produto_nome: "string"
      valor_verba_reais: "numeric"
      data_competencia: "datetime"
      arquivo_fonte: "string"
    
    validation:
      min_rows: 100  # M√≠nimo ap√≥s consolida√ß√£o
      required_columns: ["laboratorio_nome", "produto_nome", "valor_verba_reais"]
      
      range_checks:
        valor_verba_reais:
          min: 0
          max: 1000000
          message: "Verba deve estar entre R$ 0 e R$ 1.000.000"
  
  # Processamento espec√≠fico
  processing:
    data_cleaning:
      remove_duplicates: true
      duplicate_columns: ["laboratorio_nome", "produto_nome", "data_competencia"]
      
      normalize_case: "upper"
      trim_strings: true
      
      replace_values:
        "": null
        "N/A": null
        "n/a": null
        "-": null
  
  # Destino
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"
    
    # Configura√ß√£o espec√≠fica para rebates
    partitioning:
      additional_columns: ["laboratorio_nome"]  # Particionar tamb√©m por laborat√≥rio
```

### **3. Arquivo Multi-Aba (Relat√≥rio Complexo)**

```yaml
relatorio_vendas_mensal:
  name: "Relat√≥rio de Vendas Mensal Completo"
  gdrive_file_id: "1qR2sT4uV5wX6yZ7aB8cD9eF0gH1iJ2kL3mN4oP5qR6"
  
  # Configura√ß√£o por aba
  sheets:
    # Aba 1: Vendas por Produto
    vendas_produto:
      table_name: "vendas_produto_mensal"
      sheet_name: "Vendas por Produto"
      
      schema:
        column_mapping:
          "EAN": "ean_codigo"
          "Produto": "produto_nome"
          "Lab": "laboratorio_nome"
          "Qtd": "quantidade_vendida"
          "Valor": "valor_vendas"
          "Regi√£o": "regiao_venda"
        
        types:
          ean_codigo: "string"
          quantidade_vendida: "numeric"
          valor_vendas: "numeric"
          
        validation:
          min_rows: 1000
          required_columns: ["ean_codigo", "quantidade_vendida", "valor_vendas"]
          
          format_checks:
            ean_codigo:
              pattern: "^[0-9]{13}$"
    
    # Aba 2: Metas por Regi√£o
    metas_regiao:
      table_name: "metas_regiao_mensal"
      sheet_name: "Metas Regionais"
      
      schema:
        column_mapping:
          "Regi√£o": "regiao_nome"
          "Meta Quantidade": "meta_quantidade"
          "Meta Valor": "meta_valor"
          "Realizado Qtd": "realizado_quantidade"
          "Realizado Valor": "realizado_valor"
        
        types:
          meta_quantidade: "numeric"
          meta_valor: "numeric"
          realizado_quantidade: "numeric"
          realizado_valor: "numeric"
          
        validation:
          min_rows: 5  # 5 regi√µes brasileiras
          required_columns: ["regiao_nome", "meta_valor", "realizado_valor"]
    
    # Aba 3: An√°lise por Laborat√≥rio
    analise_laboratorio:
      table_name: "analise_laboratorio_mensal"
      sheet_name: "Por Laborat√≥rio"
      
      schema:
        column_mapping:
          "Laborat√≥rio": "laboratorio_nome"
          "Participa√ß√£o %": "participacao_percentual"
          "Crescimento %": "crescimento_percentual"
          "Ranking": "ranking_posicao"
        
        types:
          participacao_percentual: "numeric"
          crescimento_percentual: "numeric"
          ranking_posicao: "numeric"
          
        validation:
          min_rows: 20  # Principais laborat√≥rios
          required_columns: ["laboratorio_nome", "participacao_percentual"]
  
  # Configura√ß√£o geral
  datalake:
    bucket: "farmarcas-production-bronze"
    database: "bronze_gdrive"
```

---

## ‚úÖ Valida√ß√£o e Testes

### **Script de Valida√ß√£o do files_configs.yaml**

```python
#!/usr/bin/env python3
"""
Script para validar configura√ß√£o files_configs.yaml
"""

import yaml
import re
from pathlib import Path

def validate_files_config(config_path="files_configs.yaml"):
    """
    Valida estrutura e conte√∫do do files_configs.yaml
    """
    
    print("üîç Validando configura√ß√£o files_configs.yaml...")
    
    try:
        # Carregar arquivo
        with open(config_path) as f:
            config = yaml.safe_load(f)
        
        if not config:
            print("‚ùå Arquivo vazio ou inv√°lido")
            return False
        
        errors = []
        warnings = []
        
        # Validar cada configura√ß√£o
        for config_name, config_data in config.items():
            
            print(f"\nüìã Validando: {config_name}")
            
            # Valida√ß√µes obrigat√≥rias
            if 'name' not in config_data:
                errors.append(f"{config_name}: 'name' obrigat√≥rio")
            
            if 'table_name' not in config_data:
                errors.append(f"{config_name}: 'table_name' obrigat√≥rio")
            
            if 'datalake' not in config_data:
                errors.append(f"{config_name}: 'datalake' obrigat√≥rio")
            
            # Validar tipo de configura√ß√£o
            has_file_id = 'gdrive_file_id' in config_data
            has_folder_id = 'gdrive_folder_id' in config_data
            
            if not has_file_id and not has_folder_id:
                errors.append(f"{config_name}: Deve ter 'gdrive_file_id' ou 'gdrive_folder_id'")
            
            if has_file_id and has_folder_id:
                warnings.append(f"{config_name}: Tem ambos file_id e folder_id - ser√° tratado como pasta")
            
            # Validar IDs do Google Drive
            if has_file_id:
                file_id = config_data['gdrive_file_id']
                if not re.match(r'^[A-Za-z0-9_-]+$', file_id):
                    errors.append(f"{config_name}: gdrive_file_id inv√°lido: {file_id}")
            
            if has_folder_id:
                folder_id = config_data['gdrive_folder_id']
                if not re.match(r'^[A-Za-z0-9_-]+$', folder_id):
                    errors.append(f"{config_name}: gdrive_folder_id inv√°lido: {folder_id}")
            
            # Validar table_name
            table_name = config_data.get('table_name', '')
            if not re.match(r'^[a-z0-9_]+$', table_name):
                errors.append(f"{config_name}: table_name deve ser snake_case: {table_name}")
            
            # Validar datalake
            datalake = config_data.get('datalake', {})
            if 'bucket' not in datalake:
                errors.append(f"{config_name}: datalake.bucket obrigat√≥rio")
            if 'database' not in datalake:
                errors.append(f"{config_name}: datalake.database obrigat√≥rio")
            
            # Validar schema se presente
            if 'schema' in config_data:
                schema = config_data['schema']
                
                # Validar column_mapping
                if 'column_mapping' in schema:
                    mapping = schema['column_mapping']
                    for old_col, new_col in mapping.items():
                        if not re.match(r'^[a-z0-9_]+$', new_col):
                            warnings.append(f"{config_name}: Nova coluna deve ser snake_case: {new_col}")
                
                # Validar types
                if 'types' in schema:
                    valid_types = ['string', 'numeric', 'datetime', 'boolean']
                    types_config = schema['types']
                    for col, col_type in types_config.items():
                        if isinstance(col_type, str) and col_type not in valid_types:
                            warnings.append(f"{config_name}: Tipo inv√°lido '{col_type}' para coluna '{col}'")
            
            print(f"‚úÖ {config_name}: Configura√ß√£o v√°lida")
        
        # Relat√≥rio final
        print(f"\nüìä Resumo da valida√ß√£o:")
        print(f"   ‚úÖ Configura√ß√µes v√°lidas: {len(config)}")
        print(f"   ‚ö†Ô∏è Warnings: {len(warnings)}")
        print(f"   ‚ùå Erros: {len(errors)}")
        
        if warnings:
            print(f"\n‚ö†Ô∏è Warnings:")
            for warning in warnings:
                print(f"   - {warning}")
        
        if errors:
            print(f"\n‚ùå Erros:")
            for error in errors:
                print(f"   - {error}")
            return False
        
        print(f"\nüéâ Configura√ß√£o files_configs.yaml v√°lida!")
        return True
        
    except yaml.YAMLError as e:
        print(f"‚ùå Erro no formato YAML: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Erro na valida√ß√£o: {e}")
        return False

if __name__ == "__main__":
    validate_files_config()
```

---

**√öltima Atualiza√ß√£o**: 07/08/2025 - Configura√ß√£o alinhada com estrutura de produ√ß√£o do sistema Farmarcas
